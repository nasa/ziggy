package gov.nasa.ziggy.data.management;

import java.io.IOException;
import java.io.UncheckedIOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.StandardCopyOption;
import java.util.ArrayList;
import java.util.Date;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.stream.Collectors;

import org.apache.commons.collections.CollectionUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import gov.nasa.ziggy.data.datastore.DatastoreNode;
import gov.nasa.ziggy.data.datastore.DatastoreRegexp;
import gov.nasa.ziggy.data.datastore.DatastoreWalker;
import gov.nasa.ziggy.models.ModelImporter;
import gov.nasa.ziggy.pipeline.definition.ModelRegistry;
import gov.nasa.ziggy.pipeline.definition.ModelType;
import gov.nasa.ziggy.pipeline.definition.PipelineInstance;
import gov.nasa.ziggy.pipeline.definition.PipelineTask;
import gov.nasa.ziggy.pipeline.definition.crud.ModelCrud;
import gov.nasa.ziggy.pipeline.definition.crud.PipelineInstanceCrud;
import gov.nasa.ziggy.services.alert.AlertService;
import gov.nasa.ziggy.services.alert.AlertService.Severity;
import gov.nasa.ziggy.services.config.DirectoryProperties;
import gov.nasa.ziggy.services.database.DatabaseTransactionFactory;
import gov.nasa.ziggy.util.AcceptableCatchBlock;
import gov.nasa.ziggy.util.AcceptableCatchBlock.Rationale;
import gov.nasa.ziggy.util.io.FileUtil;

/**
 * Reference implementation of {@link DataReceiptDefinition}.
 * <p>
 * {@link DatastoreDirectoryDataReceiptDefinition} tests the delivery for conformity by validating
 * the delivery {@link Manifest} (all files present, all sizes correct, all checksums correct), and
 * ensuring that there are no files in the directory that are not listed in the manifest. Once the
 * manifest has been acknowledged, both the manifest and the acknowledgement are copied to the
 * pipeline's logs directory.
 * <p>
 * The individual files are tested for conformity by ensuring that the name of each file can be
 * translated into a location in the datastore, and that the location conforms to the directory tree
 * format of the datastore defined by {@link DatastoreNode} and {@link DatastoreRegexp} instances.
 * <p>
 * Once the validation is complete, the {@link Map} of file locations is generated by applying the
 * translation function for the data receipt filename to determine the datastore filename and
 * location.
 * <p>
 * To use {@link DatastoreDirectoryDataReceiptDefinition}, it is necessary that the path of each
 * file in the delivery directory, relative to the root of that directory, match its ultimate
 * location in the datastore, relative to the datastore directory root. In other words, if the
 * destination is (datastore-root)/foo/bar/baz, then the location in the data receipt directory must
 * be (dr-directory-root)/foo/bar/baz.
 *
 * @author PT
 */
public class DatastoreDirectoryDataReceiptDefinition implements DataReceiptDefinition {

    private Path dataImportPath;
    private Path modelsImportDirectory;
    private PipelineTask pipelineTask;
    private Manifest manifest;
    private ManifestCrud manifestCrud;
    private ModelCrud modelCrud;
    private PipelineInstanceCrud pipelineInstanceCrud;
    private Acknowledgement acknowledgement;

    private List<Path> filesForImport;
    private List<Path> failedImports = new ArrayList<>();
    private List<Path> successfulImports = new ArrayList<>();
    private List<ModelType> modelTypes;
    private ModelImporter modelImporter;

    private Logger log = LoggerFactory.getLogger(DataReceiptDefinition.class);

    @Override
    @AcceptableCatchBlock(rationale = Rationale.EXCEPTION_CHAIN)
    public boolean isConformingDelivery() {

        if (!readManifest()) {
            log.error("No manifest present in directory {}", dataImportPath.toString());
            return false;
        }

        manifest.setImportTime(new Date());
        if (pipelineTask != null) {
            manifest.setImportTaskId(pipelineTask.getId());
        } else {
            manifest.setImportTaskId(-1L);
        }

        if (!checkDatasetId()) {
            log.error("Dataset ID {} already used", manifest.getDatasetId());
            return false;
        }

        if (!acknowledgeManifest()) {
            log.error("Validation of files against the manifest status == INVALID");
            return false;
        }

        persistManifest();

        // Make sure that all the regular files in the directory tree have been validated
        // (i.e., there are no files in the directory tree that are absent from the
        // manifest).
        List<String> filesNotInManifest = filesNotInManifest();
        if (filesNotInManifest.size() != 0) {
            log.error("Data receipt directory {} contains files not listed in manifest ",
                dataImportPath.toString());
            for (String filename : filesNotInManifest) {
                log.error("File missing from manifest: {}", filename);
            }
            return false;
        }

        return true;
    }

    /** Reads the manifest and returns true if not null. */
    private boolean readManifest() {
        manifest = Manifest.readManifest(dataImportPath);
        return manifest != null;
    }

    /** Returns true if the dataset ID <= 0 or the dataset ID is not yet present in the database. */
    private boolean checkDatasetId() {
        return manifest.getDatasetId() <= 0
            || !manifestCrud().datasetIdExists(manifest.getDatasetId());
    }

    /** Generates acknowledgement and returns true if transfer status is VALID. */
    private boolean acknowledgeManifest() {
        acknowledgement = Acknowledgement.of(manifest, dataImportPath, pipelineTask.getId());

        // Write the acknowledgement to the directory.
        acknowledgement.write(dataImportPath);
        log.info("Acknowledgement file written: {}", acknowledgement.getName());
        return acknowledgementTransferStatus();
    }

    /**
     * Persists the manifest and copies the manifest and acknowledgement to the appropriate
     * directory.
     */
    private void persistManifest() {
        manifest.setAcknowledged(true);
        if (manifest.getDatasetId() > 0) {
            manifestCrud().persist(manifest);
        }

        // Create the manifests directory if it doesn't yet exist
        Path manifestDir = DirectoryProperties.manifestsDir();
        try {
            Files.createDirectories(manifestDir);

            Files.move(dataImportPath.resolve(manifest.getName()),
                manifestDir.resolve(manifest.getName()), StandardCopyOption.REPLACE_EXISTING);
            String ackName = Acknowledgement.nameFromManifestName(manifest);
            Files.move(dataImportPath.resolve(ackName), manifestDir.resolve(ackName),
                StandardCopyOption.REPLACE_EXISTING);
        } catch (IOException e) {
            throw new UncheckedIOException(e);
        }
    }

    /**
     * Returns the names of any files that are in the data receipt directory that were not in the
     * manifest.
     */
    private List<String> filesNotInManifest() {

        // Get the names of the files that passed validation (which at this point should
        // be the set of all names in the manifest)
        List<String> namesOfValidFiles = acknowledgement.namesOfValidFiles();

        Map<Path, Path> regularFilesInDirTree = FileUtil.regularFilesInDirTree(dataImportPath);
        List<String> filenamesInDirTree = regularFilesInDirTree.keySet()
            .stream()
            .map(Path::toString)
            .collect(Collectors.toList());
        filenamesInDirTree.removeAll(namesOfValidFiles);
        filenamesInDirTree.remove(manifest.getName());
        filenamesInDirTree.remove(acknowledgement.getName());
        return filenamesInDirTree;
    }

    /**
     * Returns the {@link Path}s for all files to be imported. For
     * {@link DatastoreDirectoryDataReceiptDefinition}, this is the collection of regular files in
     * the directory tree under the data import directory.
     * <p>
     * The search of the directory tree is only performed on the first call of this method. For all
     * subsequent calls, the cached results of the initial call are returned.
     */
    @Override
    public List<Path> filesForImport() {
        if (filesForImport == null) {
            filesForImport = new ArrayList<>(
                FileUtil.regularFilesInDirTree(dataImportPath).values());
        }
        return filesForImport;
    }

    /** Returns the data files for import. */
    List<Path> dataFilesForImport() {
        return filesForImport().stream()
            .filter(s -> !s.getParent().equals(modelsImportDirectory))
            .collect(Collectors.toList());
    }

    /** Returns the model files for import. */
    List<Path> modelFilesForImport() {
        return filesForImport().stream()
            .filter(s -> s.getParent().equals(modelsImportDirectory))
            .collect(Collectors.toList());
    }

    /**
     * Checks an individual file to make sure it conforms to the file name / path standards for the
     * data receipt definition. In this case, files in the models subdirectory of the data import
     * directory are checked to ensure that their names conform to the naming convention of a known
     * model type, while files in other directories are checked to ensure that the path to the given
     * file is a legal path according to the datastore definition.
     */
    @Override
    public boolean isConformingFile(Path file) {
        if (!file.isAbsolute()) {
            throw new IllegalArgumentException("Path " + file.toString() + " is not absolute");
        }
        if (file.getParent().equals(modelsImportDirectory)) {
            return isModelType(file);
        }
        Path location = dataImportPath.relativize(file).getParent();
        if (location == null) {
            return false;
        }
        return datastoreWalker().locationMatchesDatastore(location.toString());
    }

    /** Determines whether a file has the correct name to be a model of a known type. */
    private boolean isModelType(Path file) {
        for (ModelType modelType : modelTypes()) {
            if (modelType.pattern().matcher(file.getFileName().toString()).matches()) {
                return true;
            }
        }
        return false;
    }

    /**
     * Performs file import. This is accomplished with two separate methods, one of which performs
     * data file import and one of which provides model file import.
     */
    @Override
    public void importFiles() {
        importDataFiles();
        importModelFiles();
    }

    /** Imports data files into the datastore. */
    private void importDataFiles() {

        log.info("Importing data files from directory {}...", dataImportPath.toString());
        Path datastoreRoot = DirectoryProperties.datastoreRootDir().toAbsolutePath();

        List<Path> dataFilesForImport = dataFilesForImport();

        // Generate datastore paths for all data files.
        Set<Path> datastoreDirectories = new HashSet<>();
        for (Path destPath : dataFilesForImport) {
            datastoreDirectories.add(dataImportPath.relativize(destPath).getParent());
        }
        for (Path destDir : datastoreDirectories) {
            datastoreRoot.resolve(destDir).toFile().mkdirs();
        }

        int exceptionCount = 0;
        for (Path file : dataFilesForImport) {
            Path destinationFile = datastoreRoot.resolve(dataImportPath.relativize(file));
            try {
                move(file, destinationFile);
                successfulImports.add(datastoreRoot.relativize(destinationFile));
            } catch (IOException e) {
                log.error("Failed to import file " + file.toString(), e);
                exceptionCount++;
                failedImports.add(datastoreRoot.relativize(destinationFile));
            }
        }
        log.info("Importing data files from directory {}...done", dataImportPath.toString());
        if (exceptionCount > 0) {
            alertService().generateAlert("DefaultDataImporter", Severity.WARNING,
                "Data file import encountered " + exceptionCount + " data file import failures, "
                    + "see log file for details");
        }
    }

    /** Datastore file manager moveOrSymlink method broken out to facilitate unit testing. */
    void move(Path source, Path destination) throws IOException {
        FileUtil.CopyType.MOVE.copy(source, destination);
    }

    /**
     * Imports model files. This method needs to be synchronized because there may be more than one
     * task attempting to import models, in which case the tasks need to import the model files and
     * update the registry one task at a time.
     */
    private void importModelFiles() {
        synchronized (DatastoreDirectoryDataReceiptDefinition.class) {

            log.info("Importing model files from directory {}...", dataImportPath.toString());

            ModelImporter importer = modelImporter();

            // Set up and perform imports
            List<Path> modelFilesForImport = modelFilesForImport();
            importer.setDataReceiptTaskId(pipelineTask.getId());
            importer.setModelTypesToImport(modelTypes());
            importer.importModels(modelFilesForImport());

            if (!CollectionUtils.isEmpty(importer.getSuccessfulImports())) {

                // The pipeline instance is supposed to have a model registry with all the current
                // models in it. Unfortunately, the instance that contains this importer can't have
                // that registry because the models were just imported. Add the registry to the
                // instance now.
                updateModelRegistryForPipelineInstance();
                successfulImports.addAll(importer.getSuccessfulImports());
            }

            if (!CollectionUtils.isEmpty(importer.getFailedImports())) {
                failedImports.addAll(importer.getFailedImports());
                log.warn("{} out of {} model files failed to import", importer.getFailedImports(),
                    modelFilesForImport.size());
                alertService().generateAndBroadcastAlert("Data Receipt (DR)", pipelineTask.getId(),
                    AlertService.Severity.WARNING, "Failed to import " + importer.getFailedImports()
                        + " model files (out of " + modelFilesForImport.size() + ")");
            }
        }
    }

    @Override
    public List<Path> successfulImports() {
        return successfulImports;
    }

    @Override
    public List<Path> failedImports() {
        return failedImports;
    }

    // Allows a caller to supply a model importer for test purposes.
    ModelImporter modelImporter() {
        if (modelImporter == null) {
            modelImporter = new ModelImporter(dataImportPath,
                "Model imports performed at time " + new Date().toString());
        }
        return modelImporter;
    }

    // Updates the model registry in the current pipeline instance. Package scope
    // for testing purposes.
    void updateModelRegistryForPipelineInstance() {
        ModelRegistry modelRegistry = (ModelRegistry) DatabaseTransactionFactory
            .performTransaction(() -> {
                ModelCrud modelCrud = modelCrud();
                modelCrud.lockCurrentRegistry();
                ModelRegistry currentRegistry = modelCrud.retrieveCurrentRegistry();
                PipelineInstanceCrud pipelineInstanceCrud = pipelineInstanceCrud();
                PipelineInstance dbInstance = pipelineInstanceCrud
                    .retrieve(pipelineTask.getPipelineInstance().getId());
                dbInstance.setModelRegistry(currentRegistry);
                pipelineInstanceCrud.merge(dbInstance);
                return currentRegistry;
            });
        pipelineTask.getPipelineInstance().setModelRegistry(modelRegistry);
    }

    ManifestCrud manifestCrud() {
        if (manifestCrud == null) {
            manifestCrud = new ManifestCrud();
        }
        return manifestCrud;
    }

    /**
     * Sets the data import directory and, as long as we're at it, the models import directory. The
     * data import directory must be an absolute path.
     */
    @Override
    public void setDataImportDirectory(Path dataImportPath) {
        if (!dataImportPath.isAbsolute()) {
            throw new IllegalArgumentException(
                "Data import path " + dataImportPath.toString() + " is not absolute");
        }
        this.dataImportPath = dataImportPath;
        modelsImportDirectory = dataImportPath.resolve(ModelImporter.DATASTORE_MODELS_SUBDIR_NAME);
    }

    @Override
    public void setPipelineTask(PipelineTask pipelineTask) {
        this.pipelineTask = pipelineTask;
    }

    boolean acknowledgementTransferStatus() {
        return acknowledgement.getTransferStatus().equals(DataReceiptStatus.VALID);
    }

    DatastoreWalker datastoreWalker() {
        return (DatastoreWalker) DatabaseTransactionFactory
            .performTransaction(DatastoreWalker::newInstance);
    }

    ModelCrud modelCrud() {
        if (modelCrud == null) {
            modelCrud = new ModelCrud();
        }
        return modelCrud;
    }

    PipelineInstanceCrud pipelineInstanceCrud() {
        if (pipelineInstanceCrud == null) {
            pipelineInstanceCrud = new PipelineInstanceCrud();
        }
        return pipelineInstanceCrud;
    }

    List<ModelType> modelTypes() {
        if (modelTypes == null) {
            modelTypes = modelCrud().retrieveAllModelTypes();
        }
        return modelTypes;
    }

    // Allows a caller to supply an alert service instance for test purposes.
    AlertService alertService() {
        return AlertService.getInstance();
    }
}
